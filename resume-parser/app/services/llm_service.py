import json
import os
import requests
import re
from typing import Dict, Any, Optional
from app.utils.logger import logger
from app.models import ResumeData

raw_url = os.getenv("OLLAMA_BASE_URL", "http://127.0.0.1:11434")
OLLAMA_BASE_URL = raw_url.replace("localhost", "127.0.0.1")
MODEL_NAME = os.getenv("MODEL_NAME", "gemma3:1b")

def parse_with_llm(text: str) -> Optional[ResumeData]:
    """Send text to local LLM and return structured ResumeData."""
    if not text or not text.strip():
        logger.warning("Empty text provided for LLM parsing.")
        return None

    logger.info(f"Sending text to LLM (Model: {MODEL_NAME}) for parsing...")
    
    prompt = f"""
    You are an advanced AI resume parsing system. Your task is to deeply analyze the provided resume text and extract all possible relevant information with high precision and detail. Extract as much factual data as you can find. DO NOT hallucinate.

    STRICT INSTRUCTIONS:
1. Read the text carefully. Add all mentioned technologies, tools, and methods to the `"skills"` list.

2. In `"work_experience"`, include:

    Full-time jobs
    Internships
    Personal, academic, or freelance projects

   Keep the full duration exactly as written (for example, `"Jan 2020 - Present"`).
   Write clear and complete sentences describing responsibilities.

3. If an entry is a project:

    Set `"is_project"` to `true`
    Use the project name as `"role"`
    Use the course name or `"Personal Project"` as `"company"`
   `"is_project"` must be a boolean value (`true` or `false`)

4. In `"certifications"`, include official certificates or awards only.

5. In `"education"`, include GPA or honors if mentioned.

6. The final output must be valid JSON only.
   Do not include explanations or formatting.
   Return only the raw JSON object.

    The JSON schema must follow this structure exactly. Use empty strings "" or empty lists [] if the information is genuinely missing:
    {{
      "contact_information": {{
        "name": "string (Candidate's full name)",
        "email": "string",
        "phone": "string",
        "location": "string (City, State, or Country)"
      }},
      "professional_summary": "string (A detailed paragraph summarizing the candidate's career and objective)",
      "work_experience": [
        {{
          "company": "string (Company Name, or Context of Project)",
          "role": "string (Job Title, or Project Name)",
          "duration": "string",
          "responsibilities": ["string (Extract specific bullet points or detailed responsibilities)"],
          "is_project": false
        }}
      ],
      "education": [
        {{
          "degree": "string (Full degree name, e.g., Bachelor of Science in Computer Science)",
          "institution": "string",
          "year": "string"
        }}
      ],
      "skills": ["string (Individual technical and soft skills, tools, frameworks)"],
      "certifications": ["string (Name of the certification or award)"]
    }}

    Resume text to parse:
    <resume_text>
    {text}
    </resume_text>
    """
    
    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False
    }
    
    try:
        url = f"{OLLAMA_BASE_URL}/api/generate"
        logger.info(f"Connecting to Ollama at {url}")
        response = requests.post(url, json=payload, timeout=300)  # 5 minute timeout for LLM
        response.raise_for_status()
        
        result = response.json()
        output_text = result.get("response", "")
        
        # Clean markdown artifacts from LLM output
        output_text = output_text.strip()
        if output_text.startswith("```json"):
            output_text = output_text[7:]
        if output_text.startswith("```"):
            output_text = output_text[3:]
        if output_text.endswith("```"):
            output_text = output_text[:-3]
        output_text = output_text.strip()
        
        # Fix unescaped newlines generated by some smaller models (e.g. gemma3 1b)
        output_text = re.sub(r'(?<!\\)\n(?=[^"]*"[^"]*(?:"[^"]*"[^"]*)*$)', ' ', output_text)
            
        json_data = json.loads(output_text)
        resume_data = ResumeData(**json_data)
        logger.info("Successfully parsed resume data from LLM.")
        return resume_data
        
    except requests.exceptions.RequestException as e:
        logger.error(f"Failed to communicate with LLM service: {e}")
        raise RuntimeError(f"LLM Service Error: {str(e)}")
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse LLM response as JSON: {e}")
        logger.debug(f"Raw output: {output_text}")
        with open("FAILED_LLM_OUTPUT.txt", "w", encoding='utf-8') as f:
            f.write(output_text)
        raise ValueError("The LLM returned malformed JSON.")
    except Exception as e:
        logger.error(f"Unexpected error during API parse: {e}")
        raise
